{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8e61664-1da2-44eb-9875-0e4964e49a52",
   "metadata": {},
   "source": [
    "tutorial: https://www.youtube.com/watch?v=2eeYqJ0uBKE&t=1690s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6b386c-e838-4e3c-af4d-0ba460517e65",
   "metadata": {},
   "source": [
    "# 1. Setup Mario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defbdaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gym-super-mario_bros nes-py"
   ]
  },
  {
   "cell_type": "raw",
   "id": "633c03ea",
   "metadata": {},
   "source": [
    "!pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8237395-d468-4f70-8a4a-5033cb9277c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import game\n",
    "import gym_super_mario_bros\n",
    "#import the Joypad wrapper\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "#import the SIMPLIFIED constrols\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50b065d0-766a-48e8-86a4-2e51350f6126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NOOP'],\n",
       " ['right'],\n",
       " ['right', 'A'],\n",
       " ['right', 'B'],\n",
       " ['right', 'A', 'B'],\n",
       " ['A'],\n",
       " ['left']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e12b07b-9551-4b58-ad43-0394e06e94ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(256)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setup game\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea10a7ce-a155-4651-8a7f-794510250d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = JoypadSpace(env,SIMPLE_MOVEMENT)\n",
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02748729-743c-456c-96b8-46261ae77a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 256, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89be4528",
   "metadata": {},
   "source": [
    "#create a flag to check if the episode is done\n",
    "done = True\n",
    "for _ in range(1000):\n",
    "    if done:\n",
    "        #start the game\n",
    "        env.reset()\n",
    "    #step in the game\n",
    "    state, reward, done, info = env.step(env.action_space.sample())\n",
    "    # show the game in the screen\n",
    "    #env.render()\n",
    "#close the game\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e8efe13c",
   "metadata": {},
   "source": [
    "env.reset()\n",
    "print(env.step(1)[1])\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe21f5ef-9cc9-4ead-aee9-af47eb46b49a",
   "metadata": {},
   "source": [
    "# 2. Preprocess Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0cb09bc-8b44-4b8e-9549-f4e6a799d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import frame stacker wrapper and grayscaling wrapper\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "#import vectorization wrappers\n",
    "from stable_baselines3.common.vec_env import VecFrameStack,DummyVecEnv\n",
    "#import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d928d78-055f-4c00-823a-efe0f8556bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Create base environment \n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "#2. Simplify controls\n",
    "env = JoypadSpace(env,SIMPLE_MOVEMENT)\n",
    "#3. Grayscale, keep_dim to keep array shape dimension\n",
    "env = GrayScaleObservation(env,keep_dim=True)\n",
    "#4. Wrap inside the dummy environment\n",
    "env = DummyVecEnv([lambda : env])\n",
    "#5 Stack the frame\n",
    "env = VecFrameStack(env,4,channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7689d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab1d9d0b-d047-4643-ad5b-200f5768ff4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 240, 256, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "070a2d08-7e65-458e-a765-458e07f7a9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcda8c13670>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.reset()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1892fe73-5670-49c0-8015-c3a5e0190f6c",
   "metadata": {},
   "source": [
    "# 3. Train the RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e91d404b-d3d7-4354-8c8c-d5bd614ebb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os for file path management\n",
    "import os\n",
    "# Import RL model called PPO\n",
    "from stable_baselines3 import PPO\n",
    "# Import Base callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "496bd566-829d-47de-accf-f370abb2049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    \n",
    "    def __init__(self,check_freq,save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback,self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "    \n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path,exist_ok=True)\n",
    "    \n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path,f'best_model_{self.n_calls}')\n",
    "            self.model.save(model_path)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64345812-a417-4ef9-bf07-aa0baccac681",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94f067f3-60af-449e-a00a-f569839c0711",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=1e5,save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "119ea48c-a46c-47a4-be54-151d44720dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "#This is the RL model started\n",
    "model = PPO('CnnPolicy',env,verbose=1,\\\n",
    "            tensorboard_log=LOG_DIR,learning_rate=0.00001,\\\n",
    "            n_steps=16)\n",
    "#we are processing images for that reason we use cnnpoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93dcc797-a67a-4422-9f3d-f8ca20d64997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12015e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bfbe9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/PPO_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farduh/miniconda3/lib/python3.9/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 110 |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 2   |\n",
      "|    total_timesteps | 256 |\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "#model.learning_rate = 1e-3\n",
    "model.learn(total_timesteps=1e4,callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69b6f325-cc4e-4965-ae3f-301493fe9bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/PPO_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fran\\Anaconda3\\lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 67  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 7   |\n",
      "|    total_timesteps | 512 |\n",
      "----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 1024         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060868333 |\n",
      "|    clip_fraction        | 0.00996      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -0.00373     |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 169          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0066      |\n",
      "|    value_loss           | 396          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 1536        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009773324 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.0971      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.22        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    value_loss           | 1.4         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 13           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 155          |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006336387 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.139        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    value_loss           | 55.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 202          |\n",
      "|    total_timesteps      | 2560         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052634287 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.125        |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 1.55         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022357912 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.81         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.22         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 0.834        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 319          |\n",
      "|    total_timesteps      | 3584         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039665876 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -0.0189      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.138        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    value_loss           | 0.904        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 371          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009243323 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0889       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.000674    |\n",
      "|    value_loss           | 0.87         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 10           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 422          |\n",
      "|    total_timesteps      | 4608         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016033024 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.129        |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    value_loss           | 0.686        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 10           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 472          |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015428641 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.284        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.115        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    value_loss           | 0.448        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 10           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 522          |\n",
      "|    total_timesteps      | 5632         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003889728 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.0173       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.122        |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.000771    |\n",
      "|    value_loss           | 0.455        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 10           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 572          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011518993 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -0.0218      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.107        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    value_loss           | 0.32         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 10           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 623          |\n",
      "|    total_timesteps      | 6656         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017696696 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.032        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.104        |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    value_loss           | 0.217        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 10          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 672         |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010027036 |\n",
      "|    clip_fraction        | 0.0186      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.0249     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0456      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    value_loss           | 0.265       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 10           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 717          |\n",
      "|    total_timesteps      | 7680         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027416372 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | -0.0268      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0924       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 0.174        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 10           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 763          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086008515 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | -0.00536     |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0292       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    value_loss           | 0.146        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 10          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 808         |\n",
      "|    total_timesteps      | 8704        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007514999 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.0181      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 69          |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.00323     |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 10          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 854         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008901596 |\n",
      "|    clip_fraction        | 0.027       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 7.28        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.00287     |\n",
      "|    value_loss           | 71.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 10           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 899          |\n",
      "|    total_timesteps      | 9728         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0121177705 |\n",
      "|    clip_fraction        | 0.0252       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.71        |\n",
      "|    explained_variance   | -0.00119     |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.227        |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    value_loss           | 0.435        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 10          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 945         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012262092 |\n",
      "|    clip_fraction        | 0.0266      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.0268      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.136       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    value_loss           | 0.481       |\n",
      "-----------------------------------------\n",
      "Logging to ./logs/PPO_3\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 91  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 5   |\n",
      "|    total_timesteps | 512 |\n",
      "----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 20           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 1024         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068114344 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 48.3         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    value_loss           | 262          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 16           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 1536         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021220108 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | -0.0194      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0742       |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    value_loss           | 1.81         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000763117 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | -0.0351     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.219       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.000276    |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 13           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 184          |\n",
      "|    total_timesteps      | 2560         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047206213 |\n",
      "|    clip_fraction        | 0.0533       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | 0.0275       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.256        |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    value_loss           | 0.616        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004108927 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -0.149      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0908      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    value_loss           | 0.495       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 281          |\n",
      "|    total_timesteps      | 3584         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062057786 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | -0.0912      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0267       |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    value_loss           | 0.293        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010764954 |\n",
      "|    clip_fraction        | 0.00742     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | -0.0417     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0524      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    value_loss           | 0.363       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 370          |\n",
      "|    total_timesteps      | 4608         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066403337 |\n",
      "|    clip_fraction        | 0.049        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.74        |\n",
      "|    explained_variance   | 0.00811      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0744       |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00766     |\n",
      "|    value_loss           | 0.271        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 415         |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005371795 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.00437     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0364      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 460          |\n",
      "|    total_timesteps      | 5632         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031594378 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.72        |\n",
      "|    explained_variance   | -0.0262      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0581       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 0.163        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 504          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100555215 |\n",
      "|    clip_fraction        | 0.0574       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.66        |\n",
      "|    explained_variance   | -0.00544     |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.055        |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    value_loss           | 0.135        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 552         |\n",
      "|    total_timesteps      | 6656        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009859715 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.0115      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0173      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 597          |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063411146 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00497     |\n",
      "|    value_loss           | 65.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 643         |\n",
      "|    total_timesteps      | 7680        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004243778 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | -0.0669     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.155       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 688         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014331412 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.0688      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0276      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    value_loss           | 0.76        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 733         |\n",
      "|    total_timesteps      | 8704        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012275524 |\n",
      "|    clip_fraction        | 0.0418      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 778          |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034069624 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.795        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.3          |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 823          |\n",
      "|    total_timesteps      | 9728         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050160894 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.046        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.798        |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    value_loss           | 2.33         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 872         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008952736 |\n",
      "|    clip_fraction        | 0.0131      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.259       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    value_loss           | 1.6         |\n",
      "-----------------------------------------\n",
      "Logging to ./logs/PPO_4\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 90  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 5   |\n",
      "|    total_timesteps | 512 |\n",
      "----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 20           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 1024         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074637188 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.48        |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 33.8         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    value_loss           | 192          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 16           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 1536         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011454413 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 39.5         |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 14           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030693486 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | -0.0292      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.305        |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 1.8          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 13           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 2560         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047930703 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -0.227       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.199        |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    value_loss           | 1.23         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 13           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 233          |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047410913 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.0951       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.204        |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    value_loss           | 0.563        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 3584        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010044042 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | -0.263      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.247       |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    value_loss           | 1.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 327         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009955596 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.215       |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    value_loss           | 0.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 4608        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007881221 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.0734      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.383       |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    value_loss           | 0.564       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 417          |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016928371 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0.0327       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.527        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    value_loss           | 0.445        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 462          |\n",
      "|    total_timesteps      | 5632         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070053516 |\n",
      "|    clip_fraction        | 0.0283       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | -0.0578      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0627       |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    value_loss           | 0.338        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 12            |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 507           |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054701394 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | -0.0943       |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 0.0651        |\n",
      "|    n_updates            | 510           |\n",
      "|    policy_gradient_loss | -0.00081      |\n",
      "|    value_loss           | 0.408         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 558          |\n",
      "|    total_timesteps      | 6656         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040049353 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0.00649      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0424       |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    value_loss           | 0.405        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 603          |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019157492 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.947       |\n",
      "|    explained_variance   | -0.117       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0569       |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    value_loss           | 0.21         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 648         |\n",
      "|    total_timesteps      | 7680        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002193159 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 75.5        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00051    |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 693          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011777398 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.735       |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 87.6         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    value_loss           | 281          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 737          |\n",
      "|    total_timesteps      | 8704         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041652704 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.687       |\n",
      "|    explained_variance   | -0.0639      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 152          |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | 2.73e-05     |\n",
      "|    value_loss           | 363          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 782          |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015289788 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.659       |\n",
      "|    explained_variance   | 0.245        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 92           |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    value_loss           | 437          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 827          |\n",
      "|    total_timesteps      | 9728         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018543653 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.636       |\n",
      "|    explained_variance   | 0.235        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 51.8         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    value_loss           | 166          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 872          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025604935 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.661       |\n",
      "|    explained_variance   | 0.174        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 207          |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    value_loss           | 509          |\n",
      "------------------------------------------\n",
      "Logging to ./logs/PPO_5\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 89  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 5   |\n",
      "|    total_timesteps | 512 |\n",
      "----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 20           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 1024         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008299175 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 85.8         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.000196    |\n",
      "|    value_loss           | 211          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 16           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 1536         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004108639 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.802        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 98.1         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | 0.000174     |\n",
      "|    value_loss           | 209          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 14         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 140        |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00119571 |\n",
      "|    clip_fraction        | 0.00898    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.482     |\n",
      "|    explained_variance   | 0.56       |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 134        |\n",
      "|    n_updates            | 630        |\n",
      "|    policy_gradient_loss | -0.00175   |\n",
      "|    value_loss           | 300        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 13           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 2560         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013410735 |\n",
      "|    clip_fraction        | 0.00996      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 178          |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    value_loss           | 519          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002197464 |\n",
      "|    clip_fraction        | 0.024       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.515      |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00215    |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 281         |\n",
      "|    total_timesteps      | 3584        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002558032 |\n",
      "|    clip_fraction        | 0.0287      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.615      |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 326          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013407404 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.63        |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 414          |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.000991    |\n",
      "|    value_loss           | 665          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 371          |\n",
      "|    total_timesteps      | 4608         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027440335 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.602       |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 45           |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 416          |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034244023 |\n",
      "|    clip_fraction        | 0.0555       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.584       |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 53.4         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -8.71e-05    |\n",
      "|    value_loss           | 164          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 461          |\n",
      "|    total_timesteps      | 5632         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018290994 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.635       |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 55.9         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    value_loss           | 172          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 506        |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01625657 |\n",
      "|    clip_fraction        | 0.0775     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.486     |\n",
      "|    explained_variance   | 0.468      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 4.87       |\n",
      "|    n_updates            | 710        |\n",
      "|    policy_gradient_loss | 0.000957   |\n",
      "|    value_loss           | 54.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 553          |\n",
      "|    total_timesteps      | 6656         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020835763 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 68.8         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    value_loss           | 190          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 598          |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019327968 |\n",
      "|    clip_fraction        | 0.0475       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.207        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 195          |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    value_loss           | 614          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 643          |\n",
      "|    total_timesteps      | 7680         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020605528 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 76           |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 199          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 688          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014069802 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 46.7         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    value_loss           | 145          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 734          |\n",
      "|    total_timesteps      | 8704         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037337143 |\n",
      "|    clip_fraction        | 0.0369       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 47.2         |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    value_loss           | 245          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 778          |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032126042 |\n",
      "|    clip_fraction        | 0.0471       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 41.4         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 827          |\n",
      "|    total_timesteps      | 9728         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018726708 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 99.9         |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.000828    |\n",
      "|    value_loss           | 641          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 11            |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 872           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00080317806 |\n",
      "|    clip_fraction        | 0.000977      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.453        |\n",
      "|    explained_variance   | 0.843         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 39.4          |\n",
      "|    n_updates            | 790           |\n",
      "|    policy_gradient_loss | -0.000634     |\n",
      "|    value_loss           | 142           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2279ac6feb0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learning_rate = 1e-3\n",
    "model.learn(total_timesteps=1e4,callback=callback)\n",
    "model.learning_rate = 1e-4\n",
    "model.learn(total_timesteps=1e4,callback=callback)\n",
    "model.learning_rate = 1e-5\n",
    "model.learn(total_timesteps=1e4,callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4f6dd2-646f-4426-aba4-21113a9d0c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('thisisthelastestmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b949ad3-80dd-477e-ac0e-c06e68442ec5",
   "metadata": {},
   "source": [
    "# 4.Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9e4575a-a2d1-42ef-a497-7cb3019dce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load('./train/best_model_600000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ece8a1a1-b4b2-41b3-9053-21ef75272a3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "exception: access violation reading 0x000000000003C208",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22504/3403352448.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_frame_stack.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mReset\u001b[0m \u001b[0mall\u001b[0m \u001b[0menvironments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \"\"\"\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pytype:disable=annotation-type-mismatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstackedobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mVecEnvObs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_obs_from_buf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mObservationWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nes_py\\wrappers\\joypad_space.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;34m\"\"\"Reset the environment and return the initial observation.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_keys_to_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gym\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nes_py\\nes_env.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;31m# reset the emulator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_backup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nes_py\\nes_env.py\u001b[0m in \u001b[0;36m_restore\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;34m\"\"\"Restore the backup state into the NES emulator.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_will_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: exception: access violation reading 0x000000000003C208"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, _state = model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f09009af-0b3a-4733-8b43-9ec82ebb30de",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DummyVecEnv' object has no attribute 'open'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22504/1760609875.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetattr_recursive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_all_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py\u001b[0m in \u001b[0;36mgetattr_recursive\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetattr_recursive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# attribute not present, child is an unwrapped VecEnv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m             \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DummyVecEnv' object has no attribute 'open'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374725be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
